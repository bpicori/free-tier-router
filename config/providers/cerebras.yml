# Cerebras Provider Configuration
#
# API Docs: https://inference-docs.cerebras.ai/
# Cerebras offers extremely fast inference due to custom silicon.

name: cerebras
display_name: Cerebras
base_url: https://api.cerebras.ai/v1

# Default rate limits
defaults:
  limits:
    requests_per_minute: 30
    requests_per_hour: 900
    requests_per_day: 14400
    tokens_per_minute: 60000
    tokens_per_day: 1000000

# Model mappings: canonical ID -> Cerebras's model ID
models:
  # Tier 3 - Large Models
  - canonical: llama-3.3-70b
    id: llama-3.3-70b

  # Tier 1 - Small Models
  - canonical: llama-3.1-8b
    id: llama-3.1-8b
