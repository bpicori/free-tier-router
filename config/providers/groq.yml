# Groq Provider Configuration
#
# API Docs: https://console.groq.com/docs/api
# Rate Limits: https://console.groq.com/docs/rate-limits

name: groq
display_name: Groq
base_url: https://api.groq.com/openai/v1

# Default rate limits for most models
defaults:
  limits:
    requests_per_minute: 30
    requests_per_day: 14400
    tokens_per_minute: 6000
    tokens_per_day: 500000

# Model mappings: canonical ID -> Groq's model ID
models:
  # Tier 4 - XL Models
  - canonical: gpt-oss-120b
    id: openai/gpt-oss-120b
    limits:
      requests_per_day: 1000
      tokens_per_minute: 8000

  # Tier 3 - Large Models
  - canonical: llama-3.3-70b
    id: llama-3.3-70b-versatile

  # Tier 2 - Medium Models
  - canonical: qwen-3-32b
    id: qwen/qwen3-32b

  # Tier 1 - Small Models
  - canonical: llama-3.1-8b
    id: llama-3.1-8b-instant
