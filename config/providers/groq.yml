# Groq Provider Configuration
#
# API Docs: https://console.groq.com/docs/api
# Rate Limits: https://console.groq.com/docs/rate-limits

name: groq
display_name: Groq
base_url: https://api.groq.com/openai/v1

# Default rate limits for most models
defaults:
  limits:
    requests_per_minute: 30
    requests_per_day: 14400
    tokens_per_minute: 6000
    tokens_per_day: 500000

# Model mappings: canonical ID -> Groq's model ID
models:
  # Tier 5 - Frontier/Reasoning
  - canonical: deepseek-r1
    id: deepseek-r1-distill-llama-70b
    limits:
      requests_per_minute: 30
      requests_per_day: 1000
      tokens_per_minute: 6000

  # Tier 3 - Large Models
  - canonical: llama-3.3-70b
    id: llama-3.3-70b-versatile

  - canonical: llama-3.1-70b
    id: llama-3.1-70b-versatile

  # Tier 2 - Medium Models
  - canonical: qwen-2.5-32b
    id: qwen-qwq-32b

  - canonical: gemma-2-27b
    id: gemma2-27b-it

  - canonical: mistral-small-24b
    id: mistral-saba-24b

  # Tier 1 - Small Models
  - canonical: llama-3.2-3b
    id: llama-3.2-3b-preview

  - canonical: llama-3.2-1b
    id: llama-3.2-1b-preview

  - canonical: llama-3.1-8b
    id: llama-3.1-8b-instant

  - canonical: gemma-2-9b
    id: gemma2-9b-it
    limits:
      tokens_per_minute: 15000
